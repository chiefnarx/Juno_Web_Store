# ğŸ›ï¸ Juno Web Store Data Pipeline

**Juno Web Store** is a data engineering project designed to extract, transform, and load product pricing data from Jumia, an ecommerce platform. Using Python and PostgreSQL, the project performs **static HTML scraping** from multiple pages of laptop listings, and loads the structured dataset into a relational database for further analysis. 

---

## ğŸ“Œ Project Overview

This project automates product data collection and builds a clean database pipeline from live HTML sources:

âœ… Scrape product information from 50 pages of Jumia laptop listings  
âœ… Extract titles, current prices, former prices, and discount percentages  
âœ… Transform and clean the data using pandas  
âœ… Load the structured dataset into PostgreSQL using SQLAlchemy  

---

## âš™ï¸ Technologies Used

âº Python (`requests`, `BeautifulSoup`, `pandas`, `sqlalchemy`) â€” for scraping and transformation  
âº PostgreSQL â€” target database system  
âº HTML Parsing (`lxml`) â€” used with BeautifulSoup for fast scraping  

---

## ğŸ”„ Full ETL Workflow

### 1. Data Extraction and Scraping

- Fetched catalog pages with `requests`  
- Parsed HTML using BeautifulSoup  
- Extracted:
  - Product titles (`<h3 class="name">`)
  - Current prices (`<div class="prc">`)
  - Former prices (`<div class="old">`)
  - Discount percentages (`<span class="bdg_dsct _dyn -mls">`)

### 2. Data Cleaning and Transformation

- Stored extracted data into Python lists
- Structured the scraped data into a dictionary
- Converted the dictionary into a pandas DataFrame  
- Transposed and validated structure for database insertion  
- Replaced null entries in `former_price` with `'0'` and in `discount_percs` with `'0%'`

### 3. PostgreSQL Database Loading

- Defined DB parameters:
  - Username: `postgres`
  - Password: `MongoDB4luv`
  - Host: `localhost`
  - Port: `5432`
  - Database: `Juno_eCommerce`
- Constructed SQLAlchemy connection URL  
- Used `laptop_df.to_sql()` to load into PostgreSQL

---

## ğŸ“„ Results & Final Verification

âœ… Successfully scraped product data from 50 catalog pages  
âœ… Generated clean and structured DataFrame for laptops  
âœ… Created PostgreSQL-ready ingestion pipeline  

---

## ğŸ“ Notes
  
âº This scraping pipeline is built for **educational purposes**  
âº Additional fields such as brand, rating, or product URLs can be added in future versions  
âº Can be extended with Kafka for real-time data ingestion in streaming pipelines

